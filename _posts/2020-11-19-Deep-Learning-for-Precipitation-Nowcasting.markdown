---
title:  "Deep Learning for Precipitation Nowcasting"
date:   2020-11-21 18:25:42 +0900
categories: ML
defaults:
  # _posts
  - scope:
      path: ""
      type: posts
    values:
      layout: single
      author_profile: true
      read_time: true
      comments: true
      share: true
      related: true
---


## 심층신경망을 활용한 수력댐 강우 예측

데이콘을 통해 공공데이터를 활용한 수력 댐 강우예측 AI경진대회에 참여하였다.  프로젝트를 하면서 느낀 점들을 정리하고 공유하기 위해서 이 글을 작성한다. [대회에 대한 간단한 소개](#대회소개)


## 목차

### [1.참여하게 된 계기](#1-참여하게-된-계기)

### [2.팀원 소개](#2-팀원-소개)

### [3.프로젝트 진행과정](#3-프로젝트-진행과정)

### [4.개선사항](#4-개선사항)

## 1. 참여하게 된 계기



2020년 5월에 강원대학교에서 운영 중인 빅데이터 기술인재 프로그램에 참여를 했다. 약 5개월간 빅데이터 기술을 배우게 된다. 실무형 인재를 양성하는 것이 목적이기 때문에 마지막에는 프로젝트를 진행하게 된다. 개인 프로젝트를 진행하려다 실패한 적이 많았고, 팀 프로젝트의 경험은 너무 오래전이었다. 그래서 팀 프로젝트를 경험하면서 좋은 결과를 내고 싶었다. 그리고 이 프로젝트는 1등을 한 팀에게는 무려 500만원이라는 상금이 주어졌다. 결국 순위권에 들지는 못했지만 상위 20% 업적을 달성했다. 그리고 연말에 강원도에서 DATAFIRST라는 행사에 전시를 할 수 있는 기회를 갖게 됐다.


## 2. 팀원 소개


처음엔 3명에서 시작을 했다. 교육 프로그램 초기에는 인공지능 서비스를 제공하는 플랫폼을 제공하고 싶었다. 하지만 짧은 기간 내에 높은 수준의 플랫폼을 만들 자신이 없었다. 그리고 이 교육이 처음부터 끝까지 비대면 교육으로 진행이되다보니 같은 목적으로 하는 팀원을 찾는 일이 쉽지 않았다. 프로젝트 기간이 약 2주가 되기 전에 박00 교육생이 단체 카카오톡 방에 데이콘 참여 인원을 모집했다. 지원해서 같이 진행하게 됐다. 물리학 연구실에서 대학원 재학중이셨다. 같은 연구실 팀원 한 분도 같이 하기로 했지만 막바지에는 나와 박00 교육생과 단 둘이 진행하게 됐다. 



## 3. 프로젝트 진행과정

### 프로젝트 환경

- 구글 Colab

    고성능의 GPU(T4/K80),  2.2 ghz의 Xeon 2core vCPU, 13gb ram

    고 성능의 워크스테이션을 갖추려면 큰 비용이 들기때문에 저렴한 코랩환경에서 진행했다. 처음엔 무료버전을 사용했다. 하지만 학습을 오래 돌려야하고, 더 빠르게 돌리고 싶은 마음에 코랩프로를 결제했다.

- slack

    팀원들과 원활한 의사소통을 위해 slack을 사용했다. 

### 과정

대회가 본격적으로 시작된 뒤 명세서를 보면서 감을 잡지 못했다. 강우량을 예측할 때 레이저를 이용해 반사된 것을 측정하고 그에 맞춰서 반사도 이미지를 만들어낸다고 한다. 대회에서는 데이터와 정답 모두 이미지로 구성되어 있었다. 여태까지 주로 봤던 학습이 데이터가 이미지, 정답이 레이블로 구성되어 있었다. 하지만 차원 수만 늘어났을 뿐 기본적인 학습 메커니즘은 비슷했다. 정답에 맞추어 모델의 가중치가 학습되어지는 것이기 때문이다. 데이터는 총  약 62,735개의  파일이었다. 10분 간격의 5일간의 반사도 이미지(120*120)가 .npz라는 한 개의 파일로 주어졌다. 순차적인 데이터 학습에 유용한 RNN을 활용해야 겠다는 생각이 들었다.


순환뉴런신경망(RNN)을 활용하기 위해 각자 RNN과 LSTM에 대해 공부하는 시간을 가졌다. 대회에서 제공한 자료는 베이스라인 코드와 논문자료 2개가 있었다. 베이스라인 코드란 프로젝트를 진행하기 위한 약간의 가이드를 제시해주는 코드다. 대회에 참여해서 팀을 맺기 위해선 각자 1회씩 결과물을 제출해야 한다. 데이콘 대회 참여가 처음이라 모든게 낯설었다. 데이터를 불러오는 것부터 베이스라인 코드를 실행시키는 것부터 어려웠다. 3주차 부터는 다른 팀원은 ConvLSTM을 집중적으로 진행했고, 나는 RainNET에 집중했다.


<img src="/images/dacon/RainNetv1aconvolutionalneuralnetworkforradarbasedprecipitationnowcasting.png" width="450px" height="300px" alt="레인넷" align="center"/>

*레인넷*

베이스 라인은 RainNet을 축소시킨 모델이다. 처음에 돌렸을 때 점수가 너무 높게 나왔다. 레인넷 논문을 참고하였다. 저자(Georgy Ayzel)는 자신의 gitgub에 모델을 파이썬으로 구현해 놓았다. 코랩 환경에서 학습을 시켰지만 다음과 같은 오류가 떴다.

![에러](/images/dacon/error0.png)
![상세](/images/dacon/error1.png)

이 문제는 데이터 이미지의 크기때문에 발생한 문제였다. 논문상에서는 928\*928 사이즈의 이미지였고, 우리가 사용하는 데이터는 120\*120 이었다. 우리가 사용하는 모델은 FCNs(Fully Convolution Networks For Segmentation)에 기반한 모델이다. FCNs는 내부에 Skip Connection 아키텍처를 통해 입력이미지를 DownSampling한 뒤 UpSampling을 하면서 DownSampling의 결과와 결합시켜 Convolution을 진행한다. 논문에서는 928\*928 사이즈의 DownSampling이 총 4번 진행하게 된다. 그래서 이미지 사이즈가 938, 464, 232, 116, 58 순서대로 두 배씩 줄어든다. 하지만 우리 프로젝트의 데이터는 120\*120이다. 그래서 4번 진행하게 되면 120에서 60, 30, 15, 7.5 가 되는데 이미지 사이즈 크기는 정수로 표현해야 하기 때문에 7로 된다. 그래서 Upsampling을 하게 되면 14가 되는데 결합할 DownSampling에서의 이미지 사이즈인 15와 일치하지 않게 되므로 오류가 발생했던 것이다. 그래서 DownSampling을 3번으로 변경한 뒤 학습을 진행했다. 

모델을 조금씩 수정해보며 정확도를 올리려는 여러가지 시도를 해봤다. UpSampling을 진행할 때 Keras의 UpSampling보다 Conv2DTranspose가 과거의 데이터를 더 잘 학습한다는 것을 알게되서 변경시켰다. 그리고 논문에 비해 작은 사이즈의 이미지이기 때문에 레이어와 합성곱 결과인 특성 맵의 수를 줄였지만 점수 향상이 크지 않았다. 모델 내부의 학습 규제도 0.1부터 0.5까지 변경해봤지만 큰 변화가 없었다.

그러던 중 데이콘 코드 공유 게시판에서 어떤 분이 좋은 팁을 알려주셨다. 교차검증을 통해 양의 상관관계를 만들어가야 한다는 것이었다. 그래서 우리의 모델도 교차검증을 통해 학습을 시켰다. 적용 전이 0.9였다면 적용 후에는 0.7로 향상되었다. 그래서 여기서 힌트를 얻어 여러 시도를 한 끝에 기존 레인넷의 모형을 최대한 유지시켜 학습을 진행했더니 0.54까지 향상된 결과를 보였다. 계속적인 개선을 했지만 여기서 큰 변화가 생기지 않았고 새로운 방법을 찾아야 겠다고 생각했다. 이 때 더 나은 학습 환경을 위해 코랩 프로도 결제했다.

모델 학습을 개선하기 위해 RainNET 논문을 다시 읽어봤다. 힌트를 얻게됐다. 학습 파라미터, 모델 세부 구성, 모델 최적화 방법 대해 명시되어 있었다. 처음에 모델을 접했을 때 현재 내 데이터에 맞는 모델 구성을 어떻게 해야할지 몰랐다. 그래서 마음대로 모델을 구성했고 진척이 없었다. 내용은 다음과 같다.

1. Unet 기반의 아키텍처의 선수조건으로는 입력 이미지 데이터 공간 크기가 2^(n+1)의 배수여야한다. n은 MaxPooling 층의 수를 의미한다.
2. 1의 공간크기를 늘릴 때 mirror padding을 사용하고 강우량 깊이를 각 픽셀에 0.01을 더한 뒤 자연로그를 취한다.
3. RainNET과 같은 VAEs의 손실함수로서 mae 보다 logcosh이 좋은 효과를 냈다.

최종적으로 적용 시킨 것은 3번이었다. 처음에 1번을 적용한 학습 결과 이미지를 대회에 제출할 때의 이미지 크기가 다른 점에 대한 해결을 할 수 없었다. 그래서 2번과 3번을 적용시키기로 했다. 하지만 2번과 3번을 적용시켰을 때 loss가 0에 근접할 정도로 많이 떨어졌지만 뭔가 잘못됐다고 느꼈다. 2를 적용한 뒤 결과 이미지에 대한 픽셀이 전부 음수로 되는 현상이 발생됐다. 그래서 값을 변경하기 전의 값들을 살펴봤다. 이 값들은 2를 적용하면 0아니면 음수가 나올 수밖에 없는 구조였다. 그래서 결국 3번만 적용시켰다. 3번만 적용시켜서 그런건지 오히려 떨어졌다. 대회 마감이 얼마 남지 않은 상황에서 다른 방법을 시도해야 겠다고 생각했다.

대회에서 주어진 논문이 두 개가 있는데 앞서 이야기 한 것들은 RainNet이었고, 그 다음 논문은 TrajGRU 논문이었다. TrajGRU는 LSTM의 응용 모델인데 논문 내용 상으로는 기상예측시 다른 모델에 비해 저렴한 비용으로 높은 성능을 낸다는 것을 알게됐다. 이 논문 또한 코드가 넷상에 존재하였는데 케라스 구조인 Rainnet과 다르게 파이토치로 구현이 되어 있어서 대회 마감까지 구현하지 못했다.

최종적으로 대회에서 132팀 중에 26등을 했고, 데이콘 프로필에 상위 20% 업적을 세웠다. 

![순위사진](/images/dacon/순위사진.png)



## 4. 개선사항

다음 프로젝트를 진행하기 앞서 이번 프로젝트의 개선사항을 정리해보려고 한다.

1. 소스코드 관리

    어떤 요인이 학습에 영향을 줄 지 모른다. 그래서 약간씩 바뀌는 소스코드를 위해 매번 사본파일을 만들거나 한 소스코드 내에서 변경이나 셀을 추가해서 관리했다. 하지만 모두다 변화된 것들을 구분하는 게 힘들었다. 구분을 못했다. 여기서 시간낭비가 많았던 것 같다. **그렇다면 github를 이용해 소스코드 이력을 관리해야 한다.** 사실 github에 올리는 작업을 했지만, 약간씩 변경되는 코드를 매번 올리는 작업이 귀찮았다. 하지만 이를 개선할 방법이 딱히 없다. 지금 당장 생각이 난건 github에 중요한 것들을 판별해서 올려야 한다.
2. 토론방 이용

    데이콘 사이트에서 제공되는 토론 게시판을 잘 활용해야 한다. 이번 프로젝트 진행하면서 교차검증을 적용하는 방법을 통해 정확도 향상에 큰 도움이 됐다. 대부분 참여가 많이 없어보여서 나중엔 잘 보지 않았다. 하지만 대회가 끝난 뒤 토론 게시판을 보니 대회 당시 봤다면 도움이 될만한 내용과 댓글들이 있었다. **모두가 같은 어려움에 처해있었다.**
3. 대회 명세를 잘 이해할 것

    대회 주제는 정말 생소한 분야여서 난이도가 높았다. 대회 명세를 잘 이해하려는 노력을 본능적으로 회피하는 것 같다. 대회를 만든 주최는 이 정도 명세면 대회를 진행하는데 문제가 없을 것이라고 생각해서 알려준다라는 것을 느꼈다. **사실은 언제나 그 자리에 있고, 그 사실을 명확하게 이해하려는 자세를 갖춰야 한다.**
    
4. 팀원들과의 소통

    이번 대회에서 내게 팀원의 역할은 **대회진행**과 **일정관리**에서 큰 도움이 됐다. 처음에 대회에 대한 감도 잘 못잡고 있었다. 그런데 팀원이 먼저 하고 별 것 아니라고 이야기 하는 순간 진입장벽이 낮아졌다. 그리고 진행상황을 공유하는 것만으로도 일정관리가 잘 됐다. 내가 이정도 했으니 다음엔 그 전에 했던 거와 비슷한 양이나 더 넘는 양의 결과를 보여줘야한다는 마음이 들었다.

    하지만 팀원들과 코드를 공유하면서 모델 학습에 대해 이야기하는 부분이 모호했다. 이를 극복하기 위해 예/아니오 의 대답을 구하는 질문을 했다.


# 참고자료
> [Colab 무료버전 사양](https://stackoverflow.com/questions/47805170/whats-the-hardware-spec-for-google-colaboratory)

> [vCPU란?](https://www.hyve.com/what-is-a-vmware-vcpu/)

> [UpSampling 대신 Conv2DTranspose를 사용한 이유](https://stackoverflow.com/questions/53654310/what-is-the-difference-between-upsampling2d-and-conv2dtranspose-functions-in-ker#:~:text=1%20Answer&text=UpSampling2D%20is%20just%20a%20simple,operation)



# 대회소개

1. 주제

    공공데이터를 활용한 강우 예측 인공지능 알고리즘 개발

 
2. 배경

    수자원 빅데이터를 활용하여 우수한 강우예측 모델을 확보하게 되면, 수력댐의 효율적 운영과 안정성 향상이 가능합니다. 

3. 대회설명

    기상 레이더에서 관측한 구름(반사도) 이미지 데이터를 이용하여, 미래의 구름(반사도) 이미지를 예측합니다. 그리고, 예측된 구름(반사도) 이미지를 통해 국내 주요 수력댐(7개소)이 위치한 지역의 지상 강우량을 예측할 수 있습니다. 

4. 주최/운영 

    주최: 한국수력원자력㈜
    후원: 한국수자원학회
    운영: 데이콘
 
5. 참가대상 

    대한민국 거주 중이며 빅데이터를 활용한 알고리즘 개발과 학습에 관심을 보유한 일반인, 학생, 기업 등 누구나
    외국인 참가자는 심사 대상에서 제외됩니다.
    학회상은 한수원상 탈락자 중에서 한국수자원학회 학생회원 1등에게 수여됩니다. 학회 회원의 경우 “팀이름_KWRA”와 같이 팀이름 뒤에 “_KWRA”를 붙여 주시기 바랍니다. (평가 시 회원 등록 여부 확인 예정)
 
6. 데이터 출처 

    한국수력원자력(주)에서 재원을 부담하여 한국건설기술연구원(연구책임자: 윤성심)에서 수행한 연구결과입니다.(제2018-기술-20호)

 

7. 참고 문헌

    [1] Xingjian Shi, Zhihan Gao, Leonard Lausen, et al., Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model (NIPS2017) 

    https://papers.nips.cc/paper/7145-deep-learning-for-precipitation-nowcasting-a-benchmark-and-a-new-model.pdf

    

    [2] Georgy Ayzel, Tobias Scheffer, and Maik Heistermann, RainNet v1.0: a convolutional neural network for radar-based precipitation nowcasting (EGU 2020)

    https://gmd.copernicus.org/articles/13/2631/2020/gmd-13-2631-2020.pdf
